active constraint
    AI Platform
    AllReduce algorithm
    dynamic placer algorithm
    Boltzmann machines
    Hopfield networks
    restricted Boltzmann machines
    RBMs
    self-organizing maps
    SOMs
    associative memory networks
    asynchronous updates
    automatic differentiation
    autodiff
    bandwidth saturation
    canary testing
    cluster specification
    Colab Runtime
    Colaboratory
    Colab
    complementary slackness
    Compute Unified Device Architecture library
    CUDA
    concrete functions
    Contrastive Divergence
    CUDA Deep Neural Network library
    cuDNN
    computing gradients using Autodiff
    data parallelism
    data preparation
    deep belief networks
    DBNs
    Deep Learning VM Images
    Distribution Strategies API
    dual numbers
    dual problem
    embedded devices
    energy function
    data downloading
    data visualization
    framing the problem
    launching monitoring and maintaining
    Machine Learning project checklist
    model fine-tuning
    model selection and training
    exercise solutions
    fake quantization
    finite difference approximation
    forward-mode autodiff
    function definitions
    function graphs
    generalized Lagrangian
    prediction service creation
    prediction service use
    Google Cloud Storage
    GCS
    GPUs
    graphics processing units
    GPU-equipped virtual machines
    managing GPU RAM
    parallel execution across multiple devices
    placing operations and variables on devices
    selecting
    speeding computations with
    hidden units
    inequality constraints
    input signatures
    inter-op thread pool
    intra-op thread pool
    JupyterLab
    Karush–Kuhn–Tucker
    KKT
    Lagrange multipliers
    logical GPU devices
    manual differentiation
    metagraphs
    mirrored strategy
    ML Engine
    mobile devices
    model parallelism
    training across multiple devices
    stochastic neurons
    Newton's difference quotient
    NVIDIA Collective Communications Library
    NCCL
    Nvidia GPU cards
    parameter servers
    post-training quantization
    creating on GCP AI
    quantization-aware training
    queues
    ragged tensors
    reverse-mode autodiff
    SavedModel format
    service account
    sets
    spare replicas
    sparse tensors
    spurious patterns
    stale gradients
    stationary point
    string tensors
    symbolic differentiation
    symbolic tensors
    synchronous updates
    temperature
    tensor arrays
    TensorFlow cluster
    special data structures
    AutoGraph and tracing
    deploying to mobile and embedded devices
    serving TensorFlow models
    training models across multiple devices
    using GPUs to speed computations
    graphs generated by
    thermal equilibrium
    virtual GPU devices
    visible units
    warmup phase

