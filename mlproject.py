# -*- coding: utf-8 -*-
"""MLProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qoQjIigw0Ca1SongYTDtljHKp--GekwU
"""

!pip install transformers datasets torch
!pip install datasets --upgrade
!pip install opencv-python
!pip install pymupdf scikit-learn
!pip install pdfplumber

!pip install keybert

from transformers import RobertaTokenizer, RobertaForMaskedLM, RobertaConfig
import torch
from datasets import load_dataset
from keybert import KeyBERT
import numpy as np
import pdfplumber

def loadModel():
    tokenizer = RobertaTokenizer.from_pretrained("distilroberta-base")
    config = RobertaConfig.from_pretrained("distilroberta-base")
    config.gradient_checkpointing = True
    robertaModel = RobertaForMaskedLM.from_pretrained("distilroberta-base", config=config)

    return tokenizer, robertaModel

def keyBERTExtractor(text, top_n=10):
    kw_model = KeyBERT(model="all-MiniLM-L6-v2")
    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 2), stop_words='english', top_n=top_n)
    return [kw[0] for kw in keywords]

def trainTheModel(dataset_name="scientific_papers", config_name='arxiv', split='train', sample_size=1000):
    dataset = load_dataset(dataset_name, config_name, split="train[:500]", download_mode="force_redownload")
    texts = dataset["article"][:sample_size]
    tokenizer, model = loadModel()

    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors="pt")
    labels = inputs.input_ids.clone()

    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

    model.train()
    for epoch in range(3):
        optimizer.zero_grad()
        outputs = model(**inputs, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()

    return model

def extractTextFromPDF():
    pdf_path = 'sample_data/sampletext.pdf'
    text = ""
    with pdfplumber.open(pdf_path) as pdf:
        for page in pdf.pages:
            # print(len(page.extract_text()))
            text += page.extract_text()
    return text

text = extractTextFromPDF()
tokenizer, model = loadModel()
model = trainTheModel(config_name="arxiv")

keywords = keyBERTExtractor(text, top_n=10)
print("Extracted Keywords are :", keywords)





